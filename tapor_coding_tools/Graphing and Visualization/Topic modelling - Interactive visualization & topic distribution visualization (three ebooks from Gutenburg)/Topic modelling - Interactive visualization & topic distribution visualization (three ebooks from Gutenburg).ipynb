{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic modeling\n",
    "\n",
    "The books are downloaded in a directory called \"Plaintexts\" that is on the same directory as this notebook for simplicity.\n",
    "\n",
    "We use three ebook texts with different topics from Gutenburg:\n",
    "1. [Adrift in New York (children fiction)](http://www.gutenberg.org/cache/epub/18581/pg18581.txt)\n",
    "2. [Beethoven (music)](http://www.gutenberg.org/cache/epub/15141/pg15141.txt)\n",
    "3. [Sandwiches (cook)](http://www.gutenberg.org/cache/epub/29329/pg29329.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files found:\n",
      "['Plaintexts/Sandwiches.txt',\n",
      " 'Plaintexts/Beethoven.txt',\n",
      " 'Plaintexts/Adrift in New York.txt']\n",
      "\n",
      "Items in list: 3\n"
     ]
    }
   ],
   "source": [
    "import glob, os\n",
    "import codecs\n",
    "from pprint import pprint\n",
    "\n",
    "# directory with the downloaded texts\n",
    "texts_dir = \"Plaintexts\"\n",
    "# get all the .txt files in \"Plaintexts\" directory in list\n",
    "textfiles = glob.glob(os.path.join(texts_dir, \"*.txt\"), recursive=False)\n",
    "print(\"Files found:\")\n",
    "pprint(textfiles)\n",
    "\n",
    "def read_txt(filename):\n",
    "    \"\"\"Function to read the text files and return text\"\"\"\n",
    "    with codecs.open(filename,'r','utf-8') as f:\n",
    "        text = f.read()\n",
    "        return text\n",
    "\n",
    "# import the textfiles into a list\n",
    "raw_texts = []\n",
    "for textfile in textfiles:\n",
    "    raw_texts.append(read_txt(textfile))\n",
    "print(\"\\nItems in list:\", len(raw_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "We iterate through the three text files and remove stopwords, punctuation and lemmatize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "\n",
    "punctuation = set(string.punctuation) # retrieve punctuation set\n",
    "use_stopwords = stopwords.words('english')\n",
    "lemmatize = WordNetLemmatizer()\n",
    "\n",
    "clean_texts = []\n",
    "for text in raw_texts:\n",
    "    tok = \" \".join(word_tokenize(text))  # tokenize\n",
    "   \n",
    "    #remove punctuation\n",
    "    re_punc = \"\".join(i for i in tok if i not in punctuation)\n",
    "    \n",
    "    #remove stopwords\n",
    "    re_sw = \" \".join([i for i in re_punc.lower().split() if i not in use_stopwords])\n",
    "    \n",
    "    #lemmatization\n",
    "    le = \" \".join(lemmatize.lemmatize(i) for i in re_sw.split())\n",
    "    clean_texts.append(le)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the text into a matrix of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=1000, min_df=2,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
      "        strip_accents='unicode', token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer  \n",
    "\n",
    "# only consider top 1000 vocabulary ordered by \n",
    "# term frequency across the entire text corpus\n",
    "n_features = 1000\n",
    "\n",
    "#vectorize text\n",
    "tf_vectorizer = CountVectorizer(min_df = 2,\n",
    "                                strip_accents = 'unicode',\n",
    "                                max_features=n_features,\n",
    "                                stop_words='english')\n",
    "\n",
    "# learn vocabulary and return term-document matrix\n",
    "tf = tf_vectorizer.fit_transform(clean_texts)\n",
    "pprint(tf_vectorizer, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA topic modeling\n",
    "\n",
    "A brief example to explain LDA topic modeling.\n",
    "\n",
    "Suppose you have the following set of sentences:\n",
    "\n",
    "* I like to eat broccoli and bananas.\n",
    "* I ate a banana and spinach smoothie for breakfast.\n",
    "* Chinchillas and kittens are cute.\n",
    "* My sister adopted a kitten yesterday.\n",
    "* Look at this cute hamster munching on a piece of broccoli.\n",
    "\n",
    "What is Latent Dirichlet Allocation? It’s a way of automatically discovering **topics** that these sentences contain. For example, given these sentences and asked for 2 topics, LDA might produce something like\n",
    "\n",
    "* **Sentences 1 and 2:** 100% Topic A\n",
    "* **Sentences 3 and 4:** 100% Topic B\n",
    "* **Sentence 5:** 60% Topic A, 40% Topic B\n",
    "* **Topic A:** 30% broccoli, 15% bananas, 10% breakfast, 10% munching, … (at which point, you could interpret topic A to be about food)\n",
    "* **Topic B:** 20% chinchillas, 20% kittens, 20% cute, 15% hamster, … (at which point, you could interpret topic B to be about cute animals)\n",
    "\n",
    "Reference: http://blog.echen.me/2011/08/22/introduction-to-latent-dirichlet-allocation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='online', learning_offset=10.0,\n",
       "             max_doc_update_iter=100, max_iter=50, mean_change_tol=0.001,\n",
       "             n_components=3, n_jobs=1, n_topics=None, perp_tol=0.1,\n",
       "             random_state=0, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# set the topic counts\n",
    "n_topic = 3\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components = n_topic, \n",
    "                                learning_method='online',\n",
    "                                max_iter=50,\n",
    "                                random_state=0)\n",
    "lda.fit(tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing topics\n",
    "\n",
    "Using the [LDA](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html) generated above, we can derive the top words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "work time music year life man great master project friend art letter new good mind form way world thought best\n",
      "Topic #1:\n",
      "nt said mr know boy think man uncle yes like miss asked young work say time come make good sir\n",
      "Topic #2:\n",
      "bread cut add half project work salt make gutenbergtm chicken spread buttered cover press cold white book meat fish fine\n"
     ]
    }
   ],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    \"\"\"print top terms in each topic\"\"\"\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #{}:\".format(topic_idx))\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "\n",
    "# set the top n words in each topic\n",
    "n_top_words=20\n",
    "        \n",
    "# ngrams featured in the text\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the three topics, we can deduce that:\n",
    "- Topic 0: Music related\n",
    "- Topic 1: Children related\n",
    "- Topic 2: Food related"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing topic models\n",
    "We now have the data to visualize the topic models\n",
    "\n",
    "#### Visualize topic distribution\n",
    "We first get the probability of topic distrubition in the three texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[  7.62866950e-05,   7.44415098e-05,   9.99849272e-01],\n",
      "       [  9.99643034e-01,   3.29740441e-04,   2.72253200e-05],\n",
      "       [  2.78363581e-04,   9.99694149e-01,   2.74872964e-05]])\n"
     ]
    }
   ],
   "source": [
    "# topic_distribution is a distribution of the topics in each text\n",
    "topic_distribution = lda.transform(tf)\n",
    "\n",
    "pprint(topic_distribution, indent=2) # not normalized (sum of each row is not 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next we will try to visualize the topic distribution in a heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAckAAAFpCAYAAAD3I9OfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5FUhAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "flight_matrix = topic_distribution \n",
    "\n",
    "# set labels of Y axis as filenames\n",
    "yLabel = [os.path.basename(textfile) for textfile in textfiles]\n",
    "\n",
    "# set labels of X axis as topic index\n",
    "xLabel = list(range(n_topic))\n",
    "\n",
    "# add \"Topic \" to each element (1,2,3) in xLabel\n",
    "for i in range(len(xLabel)):\n",
    "    xLabel[i] = \"Topic {}\".format(xLabel[i])\n",
    "\n",
    "fig = plt.figure()\n",
    "fig, ax = plt.subplots(1,1, figsize=(6,6))\n",
    "\n",
    "ax.set_xticks(np.arange(len(xLabel)))\n",
    "ax.set_yticks(np.arange(len(yLabel)))\n",
    "\n",
    "ax.set_xticklabels(xLabel)\n",
    "ax.set_yticklabels(yLabel)\n",
    "\n",
    "heatplot = ax.imshow(flight_matrix, cmap='Purples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As we discovered above:\n",
    "    \n",
    "* Topic 0: Music related\n",
    "* Topic 1: Children related  \n",
    "* Topic 2: Food related\n",
    "\n",
    "The distribution figure shows that the topics generated are correspondent with the content of the three texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive visualization using pyLDAvis\n",
    "\n",
    "[pyLDAvis](https://github.com/bmabey/pyLDAvis) is a Python library for interactive topic model visualization. Port of the R LDAvis package. You can install it via pip as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mYou are using pip version 9.0.1, however version 10.0.1 is available.\r\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pyLDAvis>==2.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anthony/anaconda3/lib/python3.6/site-packages/pyLDAvis/_prepare.py:387: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n",
      "  topic_term_dists = topic_term_dists.ix[topic_order]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el2877438103425721095015259\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el2877438103425721095015259_data = {\"mdsDat\": {\"Freq\": [43.14484613740815, 42.326457911453815, 14.528695951138024], \"cluster\": [1, 1, 1], \"topics\": [1, 2, 3], \"x\": [-0.07052336328450468, -0.13599542186950106, 0.20651878515400574], \"y\": [-0.10031140239498026, 0.08113674079066176, 0.01917466160431864]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\"], \"Freq\": [544.0, 195.0, 500.0, 129.0, 110.0, 136.0, 371.0, 213.0, 74.0, 265.0, 152.0, 600.0, 166.0, 146.0, 54.0, 51.0, 53.0, 200.0, 50.0, 139.0, 170.0, 52.0, 57.0, 150.0, 50.0, 162.0, 204.0, 208.0, 40.0, 57.0, 89.24476778914422, 56.02078130159394, 135.15878774343398, 205.4983665524828, 34.52665835230334, 31.59651289784684, 45.27366353285937, 26.709344501044555, 25.72826747012106, 39.409281141732535, 24.760267100495533, 39.40865867180152, 51.13263494497599, 22.79816623509238, 22.804525606010003, 22.79800696769086, 35.49470368665597, 21.828912843318594, 21.826985608017473, 34.527365112516044, 20.850976815014686, 20.84890234159218, 19.87248335691023, 29.635397116261753, 18.896307442861477, 17.915492867373523, 28.665079943625628, 16.939847892913377, 26.711136852805353, 46.249568275722275, 34.52704979293786, 34.52578374342769, 33.546186381186864, 62.86450960782458, 33.54948312551591, 143.94960971668968, 198.66963169685295, 194.7242791915194, 44.302060063796105, 399.98602587221166, 58.962606065945415, 88.2682497204049, 45.26888043828251, 216.26533813506646, 53.090852334304884, 68.72570467898214, 37.460990990309824, 54.07510977704024, 150.7651386675685, 44.291490106908654, 92.16937960698591, 57.96986380395519, 73.59248755244171, 48.20862788797849, 61.880925960258224, 98.04953820190092, 80.45835181081006, 74.57094987119551, 49.168703888233715, 62.868566510238296, 62.86059841440988, 60.89882092092909, 53.08837608412395, 58.94331081864748, 55.05118086853235, 55.05640348537339, 56.02796130223559, 56.03716211256261, 56.02080941240995, 543.0565487559248, 150.64772643457349, 71.58302539304134, 142.82381521691912, 56.948527716144206, 91.107776642312, 51.080110334543136, 158.4564985858787, 29.614852695012825, 55.9633625003052, 40.35030463869478, 23.759409033559695, 78.41966134392034, 67.68249843498464, 138.9530660343519, 30.590520007346733, 18.87692339483896, 50.10820837713381, 60.85028855990347, 17.902374841498386, 38.40013986853532, 48.15885739452035, 16.925693849503812, 155.52567184581383, 24.73038460590119, 15.949455234455813, 14.973429946780096, 14.973005087298718, 14.972373703864983, 333.1684496459927, 444.4770625610694, 88.1973021136279, 61.81579795810928, 176.0543907865868, 182.86596349439228, 73.5338986180911, 55.968771972702775, 67.68023073225672, 59.88261150678097, 111.62030523817553, 142.873487663583, 64.76340083509261, 128.23699504569586, 82.32642490779949, 155.61031306416726, 84.28159252785753, 96.04114656514696, 81.37038909342995, 67.6881369780134, 91.14824847831963, 95.10484485885222, 90.19588867779618, 121.59992435056287, 99.98638881142047, 85.4128893313478, 77.49880069620527, 72.58156255637002, 193.57653425996426, 107.68547979285258, 52.59067809912129, 49.7902072208475, 48.85562984398574, 38.58744627437112, 35.78856214704809, 71.26508750991074, 122.61499200059885, 26.45745651634218, 24.585630191119094, 23.654602928332725, 22.72974660468767, 49.79639273448493, 19.919128389934308, 31.124787627032454, 28.323160297694542, 47.93147315301783, 17.12053052119661, 23.655129957981103, 13.386917237861178, 13.390031799775974, 29.252661735507374, 20.85031245464249, 12.452857693745216, 32.04927705966894, 18.054839245764818, 44.194803741392434, 17.12175276230277, 16.189572176002827, 20.856396226536955, 101.14131861007533, 45.12705977480699, 27.39455694307357, 38.59810119273567, 27.391034816621765, 33.928088397901725, 81.5501206393606, 52.610907119625715, 53.55013342606543, 78.85135763562965, 30.193312271199485, 28.33936419877997, 33.082877873769554, 27.433207434798778], \"Term\": [\"nt\", \"bread\", \"said\", \"cut\", \"add\", \"half\", \"mr\", \"music\", \"salt\", \"project\", \"yes\", \"work\", \"think\", \"miss\", \"chicken\", \"buttered\", \"spread\", \"boy\", \"cover\", \"master\", \"uncle\", \"press\", \"cold\", \"asked\", \"white\", \"gutenbergtm\", \"make\", \"know\", \"meat\", \"book\", \"art\", \"musician\", \"master\", \"music\", \"minor\", \"wrote\", \"frequently\", \"played\", \"composed\", \"occasion\", \"talent\", \"humor\", \"character\", \"greatest\", \"church\", \"ninth\", \"finally\", \"apparent\", \"greatly\", \"movement\", \"occupied\", \"stated\", \"element\", \"summer\", \"development\", \"ability\", \"performance\", \"degree\", \"spirit\", \"count\", \"brother\", \"power\", \"extent\", \"world\", \"death\", \"great\", \"year\", \"life\", \"piano\", \"work\", \"idea\", \"letter\", \"case\", \"time\", \"subject\", \"form\", \"nature\", \"people\", \"man\", \"probably\", \"friend\", \"matter\", \"mind\", \"gave\", \"best\", \"project\", \"new\", \"good\", \"given\", \"way\", \"thought\", \"come\", \"came\", \"young\", \"day\", \"gutenbergtm\", \"like\", \"make\", \"said\", \"nt\", \"yes\", \"answered\", \"miss\", \"wo\", \"sir\", \"girl\", \"think\", \"thank\", \"cousin\", \"suppose\", \"julius\", \"look\", \"dollar\", \"asked\", \"afraid\", \"expect\", \"street\", \"poor\", \"walked\", \"leave\", \"gentleman\", \"husband\", \"uncle\", \"ought\", \"drink\", \"stranger\", \"sad\", \"secretary\", \"mr\", \"said\", \"tell\", \"york\", \"boy\", \"know\", \"shall\", \"looked\", \"got\", \"let\", \"say\", \"like\", \"want\", \"young\", \"home\", \"man\", \"house\", \"come\", \"money\", \"room\", \"good\", \"make\", \"new\", \"work\", \"time\", \"project\", \"friend\", \"thought\", \"bread\", \"add\", \"chicken\", \"buttered\", \"cover\", \"meat\", \"fish\", \"salt\", \"cut\", \"mix\", \"boiled\", \"hot\", \"inch\", \"spread\", \"toast\", \"olive\", \"remove\", \"press\", \"center\", \"stir\", \"la\", \"boiling\", \"pound\", \"square\", \"caviar\", \"water\", \"tongue\", \"white\", \"tea\", \"smooth\", \"level\", \"half\", \"cold\", \"serve\", \"book\", \"cent\", \"fine\", \"project\", \"gutenbergtm\", \"make\", \"work\", \"use\", \"gutenberg\", \"mr\", \"little\"], \"Total\": [544.0, 195.0, 500.0, 129.0, 110.0, 136.0, 371.0, 213.0, 74.0, 265.0, 152.0, 600.0, 166.0, 146.0, 54.0, 51.0, 53.0, 200.0, 50.0, 139.0, 170.0, 52.0, 57.0, 150.0, 50.0, 162.0, 204.0, 208.0, 40.0, 57.0, 91.86329915782994, 57.689473145574794, 139.81163084903383, 213.13447470456447, 36.18100450352495, 33.246998504920064, 47.87153074551692, 28.357079623015995, 27.339247252820137, 42.0003501029222, 26.402676005290015, 42.04436882176718, 54.712022567725, 24.40538497269383, 24.446749083664802, 24.44722295437913, 38.1328237713038, 23.46900938006392, 23.46891128651186, 37.15580170690751, 22.491248773162877, 22.491857320358548, 21.514067576044496, 32.183907438957704, 20.536799306879082, 19.515702970177557, 31.247331266654918, 18.579582169935943, 29.334440746601715, 50.83971124572182, 38.13098588606925, 38.1313559141262, 37.11145904598286, 71.36978081087065, 37.15680168994025, 172.93688713650928, 245.09244400338332, 247.2100126594231, 50.838124405199785, 600.4373078584042, 70.34533066501798, 112.36916613092488, 52.792720307971074, 323.18570124921683, 64.31076960408615, 89.29804305136992, 43.951116101963684, 72.12262760947519, 306.7864305344701, 55.7204095308155, 170.0180921568024, 84.73643938850151, 130.93752353488767, 65.48649556635485, 101.00715538323598, 265.0125481726093, 194.34250209226346, 175.43314484003255, 71.01432740846448, 135.0538728469464, 135.80519867266224, 161.95593394965746, 108.45472299528508, 188.48117663003546, 132.2392221841597, 162.74930743286032, 203.93214448869293, 204.69214039748027, 500.9465668903665, 544.8067294659917, 152.31786430394249, 73.23503372630657, 146.46194802583977, 58.59024195840089, 94.71680817143171, 53.71104897919682, 166.97267564894534, 31.25236844604991, 59.56688699361994, 42.97015992415158, 25.393500923240104, 83.93646873982448, 73.19688703879011, 150.37852853260827, 33.20567636092081, 20.512215556996203, 54.5999369256724, 66.4055814745924, 19.537731954497968, 41.99592196997314, 52.733308590577955, 18.559026354250747, 170.8850114194349, 27.261980540995765, 17.582622511729692, 16.604603920357917, 16.60536843072604, 16.606544354217114, 371.51411826957866, 500.9465668903665, 98.54491843440131, 69.3388004508406, 200.1899465437178, 208.63347062598598, 84.87594820024435, 64.45513066304714, 79.10443775304968, 71.20865339799907, 149.4387888843941, 203.93214448869293, 80.00331277684631, 188.48117663003546, 108.28583076496167, 306.7864305344701, 125.03304647856625, 161.95593394965746, 122.95387104411054, 88.88177105570118, 175.43314484003255, 204.69214039748027, 194.34250209226346, 600.4373078584042, 323.18570124921683, 265.0125481726093, 170.0180921568024, 135.80519867266224, 195.42508382909392, 110.42134494482319, 54.29954092616341, 51.4962981947753, 50.56035119963586, 40.27972306612197, 37.47848212640639, 74.94506582566898, 129.2810992812113, 28.12958699397665, 26.26238034315571, 25.326222012854217, 24.392221796704984, 53.45249778281149, 21.587042565319724, 33.78219570618824, 30.9744904581457, 52.55931100022359, 18.785570086138275, 26.304633092874795, 15.04463242074036, 15.04819803286101, 32.88874718335356, 23.49764577146453, 14.110386609426705, 36.6676056146198, 20.69818955787981, 50.77213836279634, 19.7594593021609, 18.82607929771479, 24.47812943915901, 136.10459788246297, 57.569427865751784, 36.88383336220072, 57.86306856553115, 37.851346627395394, 56.13235260933386, 265.0125481726093, 162.74930743286032, 204.69214039748027, 600.4373078584042, 81.70942378893824, 88.62228369430575, 371.51411826957866, 119.92292581158115], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.8117, 0.8113, 0.8068, 0.8041, 0.7938, 0.7897, 0.7848, 0.7807, 0.7799, 0.7769, 0.7764, 0.7759, 0.7729, 0.7725, 0.7711, 0.7708, 0.7689, 0.7682, 0.7681, 0.7672, 0.7649, 0.7648, 0.7612, 0.7581, 0.7574, 0.7551, 0.7544, 0.7482, 0.7469, 0.746, 0.7413, 0.7413, 0.7396, 0.7137, 0.7385, 0.6571, 0.6306, 0.602, 0.703, 0.4344, 0.6641, 0.5992, 0.6869, 0.4389, 0.6489, 0.5788, 0.6808, 0.5526, 0.1302, 0.6111, 0.2283, 0.461, 0.2644, 0.5343, 0.3506, -0.1537, -0.0413, -0.0149, 0.473, 0.076, 0.0703, -0.1375, 0.1262, -0.3218, -0.0357, -0.2432, -0.4513, -0.4549, -1.3502, 0.8565, 0.8487, 0.8369, 0.8346, 0.8313, 0.8209, 0.8095, 0.8074, 0.8059, 0.7974, 0.7969, 0.7932, 0.7918, 0.7814, 0.7807, 0.7777, 0.7767, 0.7739, 0.7724, 0.7723, 0.7702, 0.769, 0.7676, 0.7656, 0.7623, 0.7623, 0.7564, 0.7563, 0.7562, 0.7508, 0.7402, 0.7488, 0.7449, 0.7313, 0.7279, 0.7163, 0.7186, 0.7038, 0.6865, 0.568, 0.5039, 0.6484, 0.4746, 0.5857, 0.181, 0.4653, 0.3372, 0.447, 0.5874, 0.205, 0.0932, 0.0921, -0.7372, -0.3134, -0.2725, 0.0741, 0.2332, 1.9195, 1.904, 1.8971, 1.8954, 1.8947, 1.8861, 1.8829, 1.8787, 1.8761, 1.8678, 1.8631, 1.8608, 1.8585, 1.8582, 1.8486, 1.8471, 1.8396, 1.8369, 1.8362, 1.8229, 1.8123, 1.8123, 1.8119, 1.8095, 1.8041, 1.7944, 1.7924, 1.7903, 1.7858, 1.7782, 1.7689, 1.6321, 1.6855, 1.6316, 1.5242, 1.6056, 1.4256, 0.7505, 0.7998, 0.5882, -0.101, 0.9335, 0.7889, -0.4895, 0.4539], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -5.0953, -5.5609, -4.6802, -4.2612, -6.0449, -6.1336, -5.7739, -6.3016, -6.3391, -5.9127, -6.3774, -5.9127, -5.6522, -6.46, -6.4597, -6.46, -6.0173, -6.5034, -6.5035, -6.0449, -6.5493, -6.5494, -6.5973, -6.1977, -6.6477, -6.701, -6.231, -6.757, -6.3016, -5.7526, -6.0449, -6.045, -6.0737, -5.4457, -6.0736, -4.6172, -4.295, -4.3151, -5.7956, -3.5952, -5.5098, -5.1063, -5.774, -4.2102, -5.6147, -5.3565, -5.9634, -5.5963, -4.5709, -5.7959, -5.063, -5.5267, -5.2881, -5.7111, -5.4614, -5.0012, -5.1989, -5.2749, -5.6914, -5.4456, -5.4457, -5.4774, -5.6147, -5.5101, -5.5784, -5.5783, -5.5608, -5.5606, -5.5609, -3.2703, -4.5526, -5.2967, -4.6059, -5.5254, -5.0555, -5.6341, -4.502, -6.1792, -5.5428, -5.8699, -6.3995, -5.2054, -5.3527, -4.6334, -6.1468, -6.6296, -5.6533, -5.4591, -6.6826, -5.9194, -5.693, -6.7387, -4.5207, -6.3595, -6.7981, -6.8612, -6.8613, -6.8613, -3.7589, -3.4706, -5.0879, -5.4434, -4.3967, -4.3588, -5.2698, -5.5427, -5.3527, -5.4751, -4.8524, -4.6056, -5.3968, -4.7136, -5.1568, -4.5202, -5.1333, -5.0027, -5.1685, -5.3526, -5.055, -5.0125, -5.0655, -4.7668, -4.9625, -5.12, -5.2172, -5.2828, -3.2326, -3.819, -4.5357, -4.5904, -4.6094, -4.8453, -4.9206, -4.2318, -3.6892, -5.2227, -5.2961, -5.3347, -5.3745, -4.5903, -5.5065, -5.0602, -5.1545, -4.6285, -5.6579, -5.3346, -5.9039, -5.9037, -5.1223, -5.4609, -5.9763, -5.0309, -5.6048, -4.7096, -5.6579, -5.7139, -5.4606, -3.8817, -4.6887, -5.1879, -4.845, -5.188, -4.974, -4.097, -4.5353, -4.5176, -4.1307, -5.0906, -5.154, -4.9992, -5.1865]}, \"token.table\": {\"Topic\": [1, 3, 1, 3, 1, 2, 1, 2, 1, 2, 1, 2, 3, 1, 2, 1, 2, 3, 1, 3, 1, 3, 1, 2, 3, 1, 2, 2, 3, 1, 2, 2, 3, 1, 2, 1, 2, 1, 3, 2, 3, 1, 3, 1, 2, 3, 2, 3, 1, 2, 1, 2, 3, 1, 2, 3, 1, 3, 1, 2, 1, 2, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 1, 2, 1, 2, 3, 1, 2, 1, 2, 1, 2, 1, 2, 3, 1, 2, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 3, 1, 3, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 3, 1, 2, 1, 2, 1, 2, 1, 2, 3, 2, 3, 1, 2, 1, 2, 3, 2, 3, 1, 2, 1, 2, 3, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 3, 1, 2, 1, 2, 1, 2, 3, 2, 3, 1, 2, 1, 2, 1, 2, 1, 3, 1, 2, 3, 1, 2, 1, 2, 3, 1, 2, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 1, 2, 3, 1, 2, 1, 3, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 1, 2, 1, 2, 3, 1, 2, 1, 2, 3, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 1, 2, 1, 2, 3, 1, 2, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 3, 1, 2, 1, 2, 3, 2, 3, 1, 2, 1, 3, 1, 2, 1, 2, 3, 1, 2, 3, 1, 3, 1, 2, 1, 2, 2, 3, 1, 2, 3, 1, 2, 1, 2, 1, 2, 1, 2, 3, 2, 3, 1, 3, 1, 2, 1, 2, 3, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 3, 1, 2, 1, 2, 1, 2, 3, 1, 2, 1, 2, 1, 2, 3], \"Freq\": [0.9223341853227761, 0.051240788073487566, 0.01811244013554976, 0.9780717673196869, 0.060230665933784906, 0.9335753219736661, 0.013654667023670566, 0.9831360257042807, 0.9374064172767432, 0.04260938260348833, 0.9688308695193875, 0.01088574010695941, 0.01088574010695941, 0.07314874076331147, 0.9243340878272995, 0.6138178999771144, 0.24750721773270742, 0.13860404193031617, 0.03807727962711545, 0.9519319906778861, 0.06645313929390634, 0.8638908108207825, 0.10369308349426497, 0.22466834757090742, 0.6740050427127222, 0.11988614021013708, 0.879165028207672, 0.005117050382716146, 0.9927077742469324, 0.9178886720782868, 0.07867617189242458, 0.019418871551071176, 0.9709435775535588, 0.4886831899640194, 0.5071240650570012, 0.8523902488352268, 0.13259403870770195, 0.07086978037383693, 0.8504373644860431, 0.2641913932003247, 0.7133167616408767, 0.05323234777622704, 0.9049499121958596, 0.9321534391617474, 0.03655503682987245, 0.018277518414936224, 0.018416361960772402, 0.9760671839209373, 0.9408203897085231, 0.04090523433515318, 0.08685165347933767, 0.12159231487107273, 0.781664881314039, 0.3766456622636704, 0.5927538291362682, 0.03087259526751397, 0.951013748094985, 0.03657745184980712, 0.9048045095628059, 0.07867865300546138, 0.05036355182236269, 0.9401196340174369, 0.01977834362842009, 0.9691388377925845, 0.03094033097057157, 0.015470165485285785, 0.9514151773450757, 0.41591291215707243, 0.4764093357435557, 0.10586874127634571, 0.9150410814073129, 0.08073891894770407, 0.9149829013651393, 0.053822523609714075, 0.9251685092737743, 0.0486930794354618, 0.05464713271044207, 0.9290012560775152, 0.013661783177610517, 0.056874337109431856, 0.9099893937509097, 0.9296242995104105, 0.046481214975520525, 0.04875143775772798, 0.9262773173968316, 0.9161590752299009, 0.05389171030764123, 0.026945855153820614, 0.91784443265748, 0.05244825329471314, 0.3028556475855457, 0.08907519046633697, 0.6057112951710913, 0.026681977050917578, 0.9605511738330329, 0.7726933048275964, 0.06719072215892143, 0.15677835170415, 0.9400158987858178, 0.020889242195240396, 0.020889242195240396, 0.5411188823078386, 0.4528929775837344, 0.7329755483917065, 0.2595955067220627, 0.0758533857804381, 0.9102406293652572, 0.03723628635096353, 0.94952530194957, 0.6900016065512928, 0.19714331615751224, 0.11265332351857842, 0.4275132847238656, 0.5187161187982904, 0.05700177129651542, 0.13905667384098083, 0.8596230746533361, 0.8326737134243217, 0.15612632126706033, 0.011564912686448913, 0.942414963981668, 0.040974563651376875, 0.9374103353760564, 0.042609560698911655, 0.349799155559245, 0.33851531183152744, 0.31594762437609225, 0.3379430663487732, 0.3379430663487732, 0.32565422757245416, 0.0514310325213631, 0.2057241300854524, 0.7420763263796676, 0.21240082693665005, 0.7572551221219698, 0.027704455687389138, 0.03948476798049288, 0.947634431531829, 0.31991542337454754, 0.6718223890865498, 0.9275915204085297, 0.047568795918386135, 0.0538821369673286, 0.9159963284445862, 0.8387194920009111, 0.14215584610184934, 0.014215584610184935, 0.04099667542934054, 0.9429235348748325, 0.039380154907463, 0.945123717779112, 0.08627570612707836, 0.8771363456252966, 0.03834475827870149, 0.0664688888391458, 0.8640955549088954, 0.07143550752725429, 0.9048497620118877, 0.12638913349052175, 0.842594223270145, 0.028086474109004833, 0.7831329806031345, 0.20468248356672836, 0.008899238415944711, 0.12255838451449379, 0.8579086916014566, 0.7888030015541808, 0.2022571798856874, 0.008090287195427495, 0.2746011431420265, 0.701213633380532, 0.02451795920910951, 0.35022494419448186, 0.41693445737438317, 0.22514460698216693, 0.04765509033265014, 0.9292742614866777, 0.011913772583162535, 0.124117349816909, 0.868821448718363, 0.2735815839887976, 0.46411161569528164, 0.26381081313205484, 0.492199083697849, 0.5084970666017513, 0.9655849029167727, 0.02860992304938586, 0.6844753026980555, 0.23602596644760532, 0.08260908825666187, 0.024826387171491483, 0.9682290996881678, 0.5651550296831683, 0.43532211745865673, 0.9673584379502262, 0.027638812512863608, 0.020483135998373588, 0.9763628159224743, 0.035549757634697185, 0.9242936985021268, 0.30905899649444335, 0.6587836504223661, 0.024399394460087633, 0.9419794054260244, 0.05382739459577282, 0.013458438735218918, 0.89633201976558, 0.08882569565244486, 0.9618340734607105, 0.03284311470353646, 0.970714359943771, 0.01733418499899591, 0.8418443780622645, 0.11376275379219791, 0.022752550758439582, 0.41164438627027794, 0.4630999345540627, 0.12349331588108338, 0.9408021533946909, 0.04090444145194308, 0.0018355133039200514, 0.9966837240285878, 0.9285636882652212, 0.02380932534013388, 0.02380932534013388, 0.9336964884341028, 0.044461737544481086, 0.05920278295095067, 0.9176431357397353, 0.9170280186505795, 0.07336224149204636, 0.7487248009375866, 0.18024856318867827, 0.06932637045718394, 0.9280792574739616, 0.0320027330163435, 0.0320027330163435, 0.8654921973380203, 0.11802166327336641, 0.9521431811365186, 0.035264562264315506, 0.07529487565609319, 0.918597483004337, 0.06081107282226573, 0.030405536411132864, 0.881760555922853, 0.917879764853414, 0.07867540841600693, 0.05707837380111847, 0.019026124600372823, 0.9132539808178955, 0.7896567948888877, 0.19741419872222193, 0.3697938104280638, 0.32073952945291245, 0.3094193107663391, 0.03228463116612849, 0.03228463116612849, 0.9039696726515976, 0.23626891938100045, 0.7650612627575252, 0.06022148825976256, 0.9033223238964384, 0.11178836966110149, 0.8863220737415904, 0.013343106567230423, 0.026686213134460846, 0.94736056627336, 0.24759301300697245, 0.7494707420751598, 0.06021722392510017, 0.9032583588765026, 0.1626728963087909, 0.08133644815439545, 0.732028033389559, 0.10603710698779668, 0.8718606574552172, 0.023563801552843707, 0.03167336461095882, 0.9607587265324175, 0.05311780451925459, 0.05311780451925459, 0.8498848723080734, 0.9204197970990072, 0.0681792442295561, 0.037416399288325346, 0.018708199644162673, 0.9354099822081337, 0.08511490978508128, 0.8937065527433534, 0.9336712260304003, 0.04446053457287621, 0.0760322332928394, 0.9123867995140728, 0.06022426098185694, 0.903363914727854, 0.03663007894537728, 0.915751973634432, 0.03663007894537728, 0.8241232429075536, 0.09329697089519474, 0.07774747574599562, 0.9321428747239638, 0.062142858314930924, 0.04654392730979553, 0.9308785461959105, 0.9468737182167074, 0.0378749487286683, 0.1012173445343861, 0.8603474285422819, 0.08118125345372713, 0.8929937879909985, 0.020295313363431784, 0.03199757489504426, 0.9599272468513278, 0.04791203092905896, 0.9462626108489146, 0.46389976684067824, 0.5375346504661828, 0.6683464001194682, 0.309419629684939, 0.02165937407794573, 0.046324085245772945, 0.9264817049154589, 0.09662680856251986, 0.8696412770626787, 0.08777832459034518, 0.9128945757395899, 0.4283471645866419, 0.20805433708494034, 0.36715471250283593, 0.051183013582586305, 0.9212942444865535, 0.16249327120066856, 0.8124663560033428, 0.024998964800102854, 0.02727202889957146, 0.08181608669871439, 0.8727049247862867, 0.466480513827223, 0.4072448930237661, 0.1258756942073459, 0.03939168340141282, 0.07878336680282565, 0.8666170348310822, 0.017067688519019953, 0.9728582455841374, 0.6661811229330348, 0.2031852424945756, 0.13157077177927437, 0.8827265445434042, 0.11209225962455925, 0.9624928997805463, 0.030077903118142072, 0.8119385353114066, 0.163203725690735, 0.02448055885361025, 0.00656521810209045, 0.991347933415658, 0.10095357800374435, 0.8941602623188786, 0.3130286061181031, 0.6791129081884272, 0.005305569595222087], \"Term\": [\"ability\", \"ability\", \"add\", \"add\", \"afraid\", \"afraid\", \"answered\", \"answered\", \"apparent\", \"apparent\", \"art\", \"art\", \"art\", \"asked\", \"asked\", \"best\", \"best\", \"best\", \"boiled\", \"boiled\", \"boiling\", \"boiling\", \"book\", \"book\", \"book\", \"boy\", \"boy\", \"bread\", \"bread\", \"brother\", \"brother\", \"buttered\", \"buttered\", \"came\", \"came\", \"case\", \"case\", \"caviar\", \"caviar\", \"cent\", \"cent\", \"center\", \"center\", \"character\", \"character\", \"character\", \"chicken\", \"chicken\", \"church\", \"church\", \"cold\", \"cold\", \"cold\", \"come\", \"come\", \"come\", \"composed\", \"composed\", \"count\", \"count\", \"cousin\", \"cousin\", \"cover\", \"cover\", \"cut\", \"cut\", \"cut\", \"day\", \"day\", \"day\", \"death\", \"death\", \"degree\", \"degree\", \"development\", \"development\", \"dollar\", \"dollar\", \"dollar\", \"drink\", \"drink\", \"element\", \"element\", \"expect\", \"expect\", \"extent\", \"extent\", \"extent\", \"finally\", \"finally\", \"fine\", \"fine\", \"fine\", \"fish\", \"fish\", \"form\", \"form\", \"form\", \"frequently\", \"frequently\", \"frequently\", \"friend\", \"friend\", \"gave\", \"gave\", \"gentleman\", \"gentleman\", \"girl\", \"girl\", \"given\", \"given\", \"given\", \"good\", \"good\", \"good\", \"got\", \"got\", \"great\", \"great\", \"great\", \"greatest\", \"greatest\", \"greatly\", \"greatly\", \"gutenberg\", \"gutenberg\", \"gutenberg\", \"gutenbergtm\", \"gutenbergtm\", \"gutenbergtm\", \"half\", \"half\", \"half\", \"home\", \"home\", \"home\", \"hot\", \"hot\", \"house\", \"house\", \"humor\", \"humor\", \"husband\", \"husband\", \"idea\", \"idea\", \"idea\", \"inch\", \"inch\", \"julius\", \"julius\", \"know\", \"know\", \"know\", \"la\", \"la\", \"leave\", \"leave\", \"let\", \"let\", \"let\", \"letter\", \"letter\", \"letter\", \"level\", \"level\", \"life\", \"life\", \"life\", \"like\", \"like\", \"like\", \"little\", \"little\", \"little\", \"look\", \"look\", \"look\", \"looked\", \"looked\", \"make\", \"make\", \"make\", \"man\", \"man\", \"master\", \"master\", \"matter\", \"matter\", \"matter\", \"meat\", \"meat\", \"mind\", \"mind\", \"minor\", \"minor\", \"miss\", \"miss\", \"mix\", \"mix\", \"money\", \"money\", \"money\", \"movement\", \"movement\", \"mr\", \"mr\", \"mr\", \"music\", \"music\", \"musician\", \"musician\", \"nature\", \"nature\", \"nature\", \"new\", \"new\", \"new\", \"ninth\", \"ninth\", \"nt\", \"nt\", \"occasion\", \"occasion\", \"occasion\", \"occupied\", \"occupied\", \"olive\", \"olive\", \"ought\", \"ought\", \"people\", \"people\", \"people\", \"performance\", \"performance\", \"performance\", \"piano\", \"piano\", \"played\", \"played\", \"poor\", \"poor\", \"pound\", \"pound\", \"pound\", \"power\", \"power\", \"press\", \"press\", \"press\", \"probably\", \"probably\", \"project\", \"project\", \"project\", \"remove\", \"remove\", \"remove\", \"room\", \"room\", \"sad\", \"sad\", \"said\", \"said\", \"salt\", \"salt\", \"salt\", \"say\", \"say\", \"secretary\", \"secretary\", \"serve\", \"serve\", \"serve\", \"shall\", \"shall\", \"shall\", \"sir\", \"sir\", \"smooth\", \"smooth\", \"smooth\", \"spirit\", \"spirit\", \"spread\", \"spread\", \"spread\", \"square\", \"square\", \"stated\", \"stated\", \"stir\", \"stir\", \"stranger\", \"stranger\", \"street\", \"street\", \"street\", \"subject\", \"subject\", \"subject\", \"summer\", \"summer\", \"suppose\", \"suppose\", \"talent\", \"talent\", \"tea\", \"tea\", \"tell\", \"tell\", \"tell\", \"thank\", \"thank\", \"think\", \"think\", \"thought\", \"thought\", \"time\", \"time\", \"time\", \"toast\", \"toast\", \"tongue\", \"tongue\", \"uncle\", \"uncle\", \"use\", \"use\", \"use\", \"walked\", \"walked\", \"want\", \"want\", \"want\", \"water\", \"water\", \"water\", \"way\", \"way\", \"way\", \"white\", \"white\", \"white\", \"wo\", \"wo\", \"work\", \"work\", \"work\", \"world\", \"world\", \"wrote\", \"wrote\", \"year\", \"year\", \"year\", \"yes\", \"yes\", \"york\", \"york\", \"young\", \"young\", \"young\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2, 3]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el2877438103425721095015259\", ldavis_el2877438103425721095015259_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el2877438103425721095015259\", ldavis_el2877438103425721095015259_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el2877438103425721095015259\", ldavis_el2877438103425721095015259_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=            Freq  cluster  topics         x         y\n",
       "topic                                                \n",
       "0      43.144846        1       1 -0.070523 -0.100311\n",
       "1      42.326458        1       2 -0.135995  0.081137\n",
       "2      14.528696        1       3  0.206519  0.019175, topic_info=     Category        Freq         Term       Total  loglift  logprob\n",
       "term                                                                \n",
       "617   Default  544.000000           nt  544.000000  30.0000  30.0000\n",
       "150   Default  195.000000        bread  195.000000  29.0000  29.0000\n",
       "790   Default  500.000000         said  500.000000  28.0000  28.0000\n",
       "234   Default  129.000000          cut  129.000000  27.0000  27.0000\n",
       "72    Default  110.000000          add  110.000000  26.0000  26.0000\n",
       "431   Default  136.000000         half  136.000000  25.0000  25.0000\n",
       "597   Default  371.000000           mr  371.000000  24.0000  24.0000\n",
       "598   Default  213.000000        music  213.000000  23.0000  23.0000\n",
       "791   Default   74.000000         salt   74.000000  22.0000  22.0000\n",
       "718   Default  265.000000      project  265.000000  21.0000  21.0000\n",
       "996   Default  152.000000          yes  152.000000  20.0000  20.0000\n",
       "986   Default  600.000000         work  600.000000  19.0000  19.0000\n",
       "916   Default  166.000000        think  166.000000  18.0000  18.0000\n",
       "586   Default  146.000000         miss  146.000000  17.0000  17.0000\n",
       "181   Default   54.000000      chicken   54.000000  16.0000  16.0000\n",
       "155   Default   51.000000     buttered   51.000000  15.0000  15.0000\n",
       "855   Default   53.000000       spread   53.000000  14.0000  14.0000\n",
       "149   Default  200.000000          boy  200.000000  13.0000  13.0000\n",
       "232   Default   50.000000        cover   50.000000  12.0000  12.0000\n",
       "566   Default  139.000000       master  139.000000  11.0000  11.0000\n",
       "942   Default  170.000000        uncle  170.000000  10.0000  10.0000\n",
       "705   Default   52.000000        press   52.000000   9.0000   9.0000\n",
       "193   Default   57.000000         cold   57.000000   8.0000   8.0000\n",
       "112   Default  150.000000        asked  150.000000   7.0000   7.0000\n",
       "975   Default   50.000000        white   50.000000   6.0000   6.0000\n",
       "428   Default  162.000000  gutenbergtm  162.000000   5.0000   5.0000\n",
       "558   Default  204.000000         make  204.000000   4.0000   4.0000\n",
       "502   Default  208.000000         know  208.000000   3.0000   3.0000\n",
       "573   Default   40.000000         meat   40.000000   2.0000   2.0000\n",
       "146   Default   57.000000         book   57.000000   1.0000   1.0000\n",
       "...       ...         ...          ...         ...      ...      ...\n",
       "634    Topic3   31.124788        olive   33.782196   1.8471  -5.0602\n",
       "766    Topic3   28.323160       remove   30.974490   1.8396  -5.1545\n",
       "705    Topic3   47.931473        press   52.559311   1.8369  -4.6285\n",
       "169    Topic3   17.120531       center   18.785570   1.8362  -5.6579\n",
       "866    Topic3   23.655130         stir   26.304633   1.8229  -5.3346\n",
       "505    Topic3   13.386917           la   15.044632   1.8123  -5.9039\n",
       "145    Topic3   13.390032      boiling   15.048198   1.8123  -5.9037\n",
       "697    Topic3   29.252662        pound   32.888747   1.8119  -5.1223\n",
       "857    Topic3   20.850312       square   23.497646   1.8095  -5.4609\n",
       "167    Topic3   12.452858       caviar   14.110387   1.8041  -5.9763\n",
       "968    Topic3   32.049277        water   36.667606   1.7944  -5.0309\n",
       "927    Topic3   18.054839       tongue   20.698190   1.7924  -5.6048\n",
       "975    Topic3   44.194804        white   50.772138   1.7903  -4.7096\n",
       "905    Topic3   17.121753          tea   19.759459   1.7858  -5.6579\n",
       "839    Topic3   16.189572       smooth   18.826079   1.7782  -5.7139\n",
       "528    Topic3   20.856396        level   24.478129   1.7689  -5.4606\n",
       "431    Topic3  101.141319         half  136.104598   1.6321  -3.8817\n",
       "193    Topic3   45.127060         cold   57.569428   1.6855  -4.6887\n",
       "814    Topic3   27.394557        serve   36.883833   1.6316  -5.1879\n",
       "146    Topic3   38.598101         book   57.863069   1.5242  -4.8450\n",
       "168    Topic3   27.391035         cent   37.851347   1.6056  -5.1880\n",
       "366    Topic3   33.928088         fine   56.132353   1.4256  -4.9740\n",
       "718    Topic3   81.550121      project  265.012548   0.7505  -4.0970\n",
       "428    Topic3   52.610907  gutenbergtm  162.749307   0.7998  -4.5353\n",
       "558    Topic3   53.550133         make  204.692140   0.5882  -4.5176\n",
       "986    Topic3   78.851358         work  600.437308  -0.1010  -4.1307\n",
       "947    Topic3   30.193312          use   81.709424   0.9335  -5.0906\n",
       "427    Topic3   28.339364    gutenberg   88.622284   0.7889  -5.1540\n",
       "597    Topic3   33.082878           mr  371.514118  -0.4895  -4.9992\n",
       "543    Topic3   27.433207       little  119.922926   0.4539  -5.1865\n",
       "\n",
       "[201 rows x 6 columns], token_table=      Topic      Freq      Term\n",
       "term                           \n",
       "59        1  0.922334   ability\n",
       "59        3  0.051241   ability\n",
       "72        1  0.018112       add\n",
       "72        3  0.978072       add\n",
       "82        1  0.060231    afraid\n",
       "82        2  0.933575    afraid\n",
       "94        1  0.013655  answered\n",
       "94        2  0.983136  answered\n",
       "97        1  0.937406  apparent\n",
       "97        2  0.042609  apparent\n",
       "109       1  0.968831       art\n",
       "109       2  0.010886       art\n",
       "109       3  0.010886       art\n",
       "112       1  0.073149     asked\n",
       "112       2  0.924334     asked\n",
       "139       1  0.613818      best\n",
       "139       2  0.247507      best\n",
       "139       3  0.138604      best\n",
       "144       1  0.038077    boiled\n",
       "144       3  0.951932    boiled\n",
       "145       1  0.066453   boiling\n",
       "145       3  0.863891   boiling\n",
       "146       1  0.103693      book\n",
       "146       2  0.224668      book\n",
       "146       3  0.674005      book\n",
       "149       1  0.119886       boy\n",
       "149       2  0.879165       boy\n",
       "150       2  0.005117     bread\n",
       "150       3  0.992708     bread\n",
       "152       1  0.917889   brother\n",
       "...     ...       ...       ...\n",
       "964       2  0.812466      want\n",
       "964       3  0.024999      want\n",
       "968       1  0.027272     water\n",
       "968       2  0.081816     water\n",
       "968       3  0.872705     water\n",
       "969       1  0.466481       way\n",
       "969       2  0.407245       way\n",
       "969       3  0.125876       way\n",
       "975       1  0.039392     white\n",
       "975       2  0.078783     white\n",
       "975       3  0.866617     white\n",
       "982       1  0.017068        wo\n",
       "982       2  0.972858        wo\n",
       "986       1  0.666181      work\n",
       "986       2  0.203185      work\n",
       "986       3  0.131571      work\n",
       "988       1  0.882727     world\n",
       "988       2  0.112092     world\n",
       "994       1  0.962493     wrote\n",
       "994       2  0.030078     wrote\n",
       "995       1  0.811939      year\n",
       "995       2  0.163204      year\n",
       "995       3  0.024481      year\n",
       "996       1  0.006565       yes\n",
       "996       2  0.991348       yes\n",
       "997       1  0.100954      york\n",
       "997       2  0.894160      york\n",
       "998       1  0.313029     young\n",
       "998       2  0.679113     young\n",
       "998       3  0.005306     young\n",
       "\n",
       "[364 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 2, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.sklearn.prepare(lda, tf, tf_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Understanding the visualizations\n",
    "- The size of the circle represents the documents in each topic\n",
    "- The bars in the left part show the most frequent keywords in each topic\n",
    "- The distance among the circles shows the similarity of different topics\n",
    "- Set λ = 1, the words with high frequency are more relevant to the topic,\n",
    "- Set λ = 0, words more exclusive are more relavent to the topic.\n",
    "\n",
    "### About pyLDAvis\n",
    "\n",
    "[pyLDAvis](http://pyldavis.readthedocs.io/en/latest/modules/API.html) is designed to help users interpret the topics in a topic model that has been fit to a corpus of text data. The\n",
    "package extracts information from a fitted LDA topic model to inform an interactive web-based visualization\n",
    "\n",
    "It answers three questions:\n",
    " 1. What is the meaning of each topic?\n",
    " 2. How prevalent is each topic?\n",
    " 3. How do the topics relate to each other?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
